// Each #kernel tells which function to compile; you can have many kernels
#pragma use_dxc
#pragma enable_d3d11_debug_symbols

#pragma kernel CSMain

#include "UnityCG.cginc"
#include "../RandomSequence.hlsl"
#include "../Common.hlsl"

Texture2D<float> _depth_texture;
Texture2D _position_texture;
Texture2D _normal_texture;

SamplerState _inline_point_clamp_sampler;
SamplerState _inline_linear_clamp_sampler;
float4 _camera_pixel_size_and_screen_size;
float4x4 _view_projection_matrix;
float4x4 _projection_matrix;
float4x4 _world_to_camera_matrix;
float4x4 _camera_to_world_matrix;
float4x4 _camera_to_screen_matrix;
int frame_index;

RWTexture2D<float4> _output_texture;

float get_linearized_depth(float2 texcoord)
{
    float depth = _depth_texture.SampleLevel(_inline_point_clamp_sampler, texcoord, 0).x;
    return LinearEyeDepth(depth);
}

float4 projection_space_position_from_camera_space_position(float3 position)
{
    return mul(_projection_matrix, float4(position, 1.0));
}

float4 projection_space_vector_from_camera_space_vector(float3 v)
{
    return mul(_projection_matrix, float4(v, 0.0));
}

float4 screen_space_position_from_camera_space_position(float3 position)
{
    return mul(_camera_to_screen_matrix, float4(position, 1.0));
}

static const uint ray_sample_per_pixel = 4;
static const float camera_near_z = 0.1;
static const float ray_marching_thickness = 0.5;
static const uint ray_marching_sample_count = 8;
static const float ray_marching_width = 128;

float ground_truth_visibility_mask_ao(inout random_sampler_state rng, float3 camera_space_position, float3 camera_space_normal)
{
    float occ = 0.0;
    return 0.0;
}

float reference_ssao(inout random_sampler_state rng, float3 camera_space_position, float3 camera_space_normal)
{
    float occlusion = 0.0;
    for (uint sample_index = 0; sample_index < ray_sample_per_pixel; sample_index++)
    {
        float2 xy = sample_uniform_rng_2d(rng);
        float3 sample_direction = sample_sphere(xy);
        // cosine weighted hemisphere
        sample_direction = normalize(sample_direction + camera_space_normal);
        float4 h0 = screen_space_position_from_camera_space_position(camera_space_position);
        float4 h1 = screen_space_position_from_camera_space_position(camera_space_position + sample_direction * camera_near_z * 0.5);
        
        float k0 = 1.0 / h0.w;
        float k1 = 1.0 / h1.w;
        
        float2 p0 = h0.xy * k0;
        float2 p1 = h1.xy * k1;
        
        float2 dp = p1 - p0;
        float dk = k1 - k0;
            
        float2 derivative_of_p_with_respect_to_uv = dp * _camera_pixel_size_and_screen_size.zw;
        float one_over_length_of_derivative_of_p_with_respect_to_uv = rsqrt(dot(derivative_of_p_with_respect_to_uv, derivative_of_p_with_respect_to_uv));

        // 1 px step size
        dp = dp * one_over_length_of_derivative_of_p_with_respect_to_uv;
        dk = dk * one_over_length_of_derivative_of_p_with_respect_to_uv;
            
        float random_sample = sample_uniform_rng(rng);
        
        const float step_size = pow(ray_marching_width, 1.0 / ray_marching_sample_count);
            
        float t = pow(step_size, random_sample);// init t: [1, s]

        for (float i = 0.0; i < ray_marching_sample_count; i++)
        {
            float2 uv = p0 + dp * t;
            if (any(uv < 0) || any(uv >= 1))
            {
                break;
            }
            float k = k0 + dk * t;

            // exponential step size
            t *= step_size;

            float estimated_depth = 1.0 / k;
            float depth_sample = get_linearized_depth(uv);
            if((estimated_depth > depth_sample) && (estimated_depth < (depth_sample + ray_marching_thickness)))
            {
                occlusion += 1.0;
                break;
            }
        }
    }
    occlusion /= float(ray_sample_per_pixel);
    return 1.0 - occlusion;
}

[numthreads(8,8,1)]
void CSMain (uint2 id : SV_DispatchThreadID)
{
    if (any(id.xy >= _camera_pixel_size_and_screen_size.zw))
    {
        return;
    }

    random_sampler_state rng = init_random_sampler(id, frame_index);
    float2 uv = (id.xy + 0.5) / _camera_pixel_size_and_screen_size.zw;
    
    float3 world_space_position = _position_texture.SampleLevel(_inline_point_clamp_sampler, uv, 0).xyz;
    float3 camera_space_position = mul(_world_to_camera_matrix, float4(world_space_position, 1.0)).xyz;
    
    float3 world_space_normal = _normal_texture.SampleLevel(_inline_point_clamp_sampler, uv, 0).xyz;
    float3 camera_space_normal = normalize(mul(transpose((float3x3)_camera_to_world_matrix), world_space_normal).xyz);
    
    float ao = reference_ssao(rng, camera_space_position, camera_space_normal);
    _output_texture[id.xy] = float4(ao, ao, ao, 0.0);
}
