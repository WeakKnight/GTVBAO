// Each #kernel tells which function to compile; you can have many kernels
#pragma use_dxc
#pragma enable_d3d11_debug_symbols

#pragma kernel CSMain

#include "UnityCG.cginc"
#include "../RandomSequence.hlsl"
#include "../Common.hlsl"

Texture2D<float> _depth_texture;
Texture2D _position_texture;
Texture2D _normal_texture;

SamplerState _inline_point_clamp_sampler;
SamplerState _inline_linear_clamp_sampler;
float4 _camera_pixel_size_and_screen_size;
float4x4 _view_projection_matrix;
float4x4 _projection_matrix;
float4x4 _world_to_camera_matrix;
float4x4 _camera_to_world_matrix;
float4x4 _camera_to_screen_matrix;

RWTexture2D<float4> _output_texture;

float get_linearized_depth(float2 texcoord)
{
    float depth = _depth_texture.SampleLevel(_inline_point_clamp_sampler, texcoord, 0).x;
    return LinearEyeDepth(depth);
}

float4 projection_space_position_from_camera_space_position(float3 position)
{
    return mul(_projection_matrix, float4(position, 1.0));
}

float4 projection_space_vector_from_camera_space_vector(float3 v)
{
    return mul(_projection_matrix, float4(v, 0.0));
}

static const uint ray_sample_per_pixel = 4;
static const float camera_near_z = 0.1;
static const float ray_marching_thickness = 0.5;
static const uint ray_marching_sample_count = 16;
static const float ray_marching_width = 512;

float reference_ssao(inout random_sampler_state rng, float3 camera_space_position, float3 camera_space_normal)
{
    float occ = 0.0;
    for (uint sample_index = 0; sample_index < ray_sample_per_pixel; sample_index++)
    {
        float2 xy = sample_uniform_rng_2d(rng);
        float3 rayDir = sample_sphere(xy);
        // cosine weighted hemisphere
        rayDir = normalize(rayDir + camera_space_normal);
        float4 rayStart = projection_space_position_from_camera_space_position(camera_space_position);
        float4 rayEnd = projection_space_position_from_camera_space_position(camera_space_position + rayDir * camera_near_z * 0.5);
        
        float rwStart = 1.0 / rayStart.w;
        float rwEnd   = 1.0 / rayEnd.w;
            
        float2 tcStart = rayStart.xy * rwStart * 0.5 + 0.5;
        float2 tcEnd   = rayEnd.xy   * rwEnd   * 0.5 + 0.5;
            
        float2  tcDelta0 = tcEnd - tcStart;
        float rwDelta0 = rwEnd - rwStart;
            
        float2  uvDelta0 = tcDelta0 * _camera_pixel_size_and_screen_size.zw;
        float uvDelta0RcpLen = rsqrt(dot(uvDelta0, uvDelta0));

        // 1 px step size
        float2  tcDelta = tcDelta0 * uvDelta0RcpLen;
        float rwDelta = rwDelta0 * uvDelta0RcpLen;
            
        float random_sample = sample_uniform_rng(rng);
        
        const float step_size = pow(ray_marching_width, 1.0/ray_marching_sample_count);
            
        float t = pow(step_size, random_sample);// init t: [1, s]

        for (float i = 0.0; i < ray_marching_sample_count; ++i)
        {
            float2  tc = tcStart + tcDelta * t;
            float rw = rwStart + rwDelta * t;

            t *= step_size;

            float depth = 1.0 / rw;
            // handle oob
            if(tc.x < 0.0 || tc.x >= 1.0 || tc.y < 0.0 || tc.y >= 1.0)
            {
                break;
            }
            float sampleDepth = get_linearized_depth(tc.xy);
            if(depth > sampleDepth && depth < (sampleDepth + ray_marching_thickness))
            {
                occ += 1.0;
                break;
            }
        }
    }
    occ /= float(ray_sample_per_pixel);
    float ao = 1.0 - occ;
    return ao;
}

[numthreads(8,8,1)]
void CSMain (uint2 id : SV_DispatchThreadID)
{
    if (any(id.xy >= _camera_pixel_size_and_screen_size.zw))
    {
        return;
    }

    random_sampler_state rng = init_random_sampler(id, 0u);
    float2 uv = (id.xy + 0.5) / _camera_pixel_size_and_screen_size.zw;
    
    float3 world_space_position = _position_texture.SampleLevel(_inline_point_clamp_sampler, uv, 0).xyz;
    float3 camera_space_position = mul(_world_to_camera_matrix, float4(world_space_position, 1.0)).xyz;
    
    float3 world_space_normal = _normal_texture.SampleLevel(_inline_point_clamp_sampler, uv, 0).xyz;
    float3 camera_space_normal = normalize(mul(transpose((float3x3)_camera_to_world_matrix), world_space_normal).xyz);
    
    float ao = reference_ssao(rng, camera_space_position, camera_space_normal);
    _output_texture[id.xy] = float4(ao, ao, ao, 0.0);
}
